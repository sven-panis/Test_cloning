---
title: "Exercise4"
author: "sven panis"
date: "2024-04-29"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This file builds Bayesian hazard models for the first experiment of Panis and Schmidt (2016) using only the nomask conditions (prime = neutral, congruent, or incongruent).

# load the libraries that we will be using #

```{r load-pkg}
pkg <- c("cmdstanr", "standist", "tidyverse", "RColorBrewer", "patchwork", 
         "brms", "tidybayes", "bayesplot", "future", "parallel")

lapply(pkg, library, character.only = TRUE)
```

# set options #

```{r set-options}
options(brms.backend = "cmdstanr",
        mc.cores = parallel::detectCores(),
        future.fork.enable = TRUE,
        future.rng.onMisuse = "ignore") ## automatically set in RStudio

supportsMulticore()

detectCores()

#check info if needed
packageVersion("cmdstanr")

devtools::session_info("rstan")
```

## read in person-trial-bin dataset (assuming independent observations) and create factors where necessary ##

```{r}
ptb_data_ind <- read_csv("data/inputfile_hazard_modeling_ind.csv")
head(ptb_data_ind)
summary(ptb_data_ind) # 26602 rows: 2757 independent trials, 3 conditions, 15 periods, and event indicator (0/1)

# select time bins 6-15 containing enough data (see also figure_for_ind1.pdf)
ptb_data_ind %>% group_by(period, event) %>% summarize(N = n())

ptb_data_ind <- ptb_data_ind %>% filter(period > 5) # 12840 rows left: 2757 trials, 10 periods
summary(ptb_data_ind)

# create dummy variables for each time period and level of condition
ptb_data_ind <- ptb_data_ind %>% 
                    mutate(d6 = if_else(period == 6, 1, 0),
                           d7 = if_else(period == 7, 1, 0),
                           d8 = if_else(period == 8, 1, 0),
                           d9 = if_else(period == 9, 1, 0),
                           d10 = if_else(period == 10, 1, 0),
                           d11 = if_else(period == 11, 1, 0),
                           d12 = if_else(period == 12, 1, 0),
                           d13 = if_else(period == 13, 1, 0),
                           d14 = if_else(period == 14, 1, 0),
                           d15 = if_else(period == 15, 1, 0),
                           con = if_else(condition == 2, 1, 0),
                           incon = if_else(condition == 3, 1, 0))
head(ptb_data_ind)

# create period_factor
ptb_data_ind <- ptb_data_ind %>% mutate(period_factor = factor(period, levels = c(6:15)))
head(ptb_data_ind)
```

## build some models ##

We start with a logit link and two dichotomous predictors (con, incon), and assume that 
(a) logit hazard is general with time (one intercept for each bin),
(b) for each predictor value, the logit hazard functions has an identical shape,
(c) the distance between each of the logit hazard functions is identical in each time bin (or period).

## b0.general - intercepts only ##

# formula #

```{r b0.general-formula}
formula = bf(event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15)
```

# check the priors available #

```{r b0.general-get-priors}
get_prior(formula,
          data = ptb_data_ind, family = binomial(link=logit))
```

## visualise priors ##

here we would normally visualise priors of interest to make a judgment about what
would constitute weakly informative priors. 

```{r b0.general-vis-priors}
visualize("normal(0, 0.5)", "normal(0, 1)", "normal(0, 2)", "normal(0,4)", 
          xlim = c(-8, 8))
```

(0,4) for the intercepts provides good coverage for what we might expect
for the logit hazard in each bin (between -8 and 8).

# visualize logit and cloglog links

```{r}
probability <- (1:99999)/100000
logistic <- function(x) { return( 1/(1+exp(-1*x)) )}
logit    <- function(x) { return( log(x/(1-x)) )}
inverse_cloglog <- function(x) { return( 1-(exp(-1*exp(x))) )}
cloglog    <- function(x) { return( log(-1*log(1-x)) )}

cloglog_prob <- cloglog(probability)
logit_prob <- logit(probability)
dataplot <- cbind(probability,cloglog_prob,logit_prob)

ggplot() +
  geom_hline(yintercept=0, color="white") +
  geom_line(data=dataplot,aes(y=logit_prob,x=probability,colour="logit"),linewidth=1) +
  geom_line(data=dataplot,aes(y=cloglog_prob,x=probability,colour="cloglog"),linewidth=1) +
  scale_color_manual(name = "Link function:", values = c("logit" = "darkblue", "cloglog" = "red")) +
  geom_vline(xintercept = logistic(0), linetype="dotted", size = 0.3) +   
  geom_vline(xintercept = inverse_cloglog(0), linetype="dotted", size = 0.3) +
  annotate("text", x = logistic(0)-.02, y = -6, label = "logistic(0) = 0.5", angle = 90) +
  annotate("text", x = inverse_cloglog(0)+.02, y = -6, label = "inverse_cloglog(0) = 0.6321", angle=90) +
  scale_x_continuous(n.breaks=10, limits = c(0,1), ) +
  labs(x = "Probability",
        y = "logit or cloglog scale") +
  theme(panel.grid = element_blank(),
        axis.text=element_text(size=12),
        axis.title=element_text(size=14),
      #  legend.position="top",
        legend.text = element_text(size=14),
        legend.position=c(.2,.75),
      legend.background = element_rect(fill="white") )
```



## set priors ##

```{r b0.general-set-priors}
priors <- c(
  set_prior("normal(0, 4)", class = "b")
)
```

# run the first model #

```{r b0.general1-model}
plan(multicore)
b0.general1 <- brm(formula = formula,
                data = ptb_data_ind, family = binomial(link = logit),
                prior = priors,
                iter = 3000, warmup = 1000, cores = 8, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b0.general1") # iter=3000 for general1 / 2000 for general had Rhat=1.1
summary(b0.general1)
```

## take a look ##

chains

```{r b0.general1-chains}
plot(b0.general1)
```






## Run a second model including the experimental factor PRIME with three levels (using both dichotomous variables con and incon)

```{r b1.general1-prime-formula}
formula = bf(event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15 + con +incon)
```

# check the priors available #

```{r b1.general-prime-get-priors}
get_prior(formula,
          data = ptb_data_ind, family = binomial(link=logit))
```

## visualise priors ##

here we would normally visualise priors of interest to make a judgment about what
would constitute weakly informative priors. 

```{r b1.general1-prime-vis-priors}
visualize("normal(-1, 0.5)", "normal(-1, 1)", "normal(-2, 2)", "normal(-1,4)", "skew_normal(-1,3,-0.5)" ,
          xlim = c(-8, 8))
```

N(-2,2) for the intercept provides good coverage for what we might expect for the cloglog hazard in each bin: -7.5 until 2.5

(0,4) for the intercepts provides good coverage for what we might expect
for the logit hazard in each bin.

## set priors ##

```{r b1.general1-prime-set-priors}
priors <- c(
  set_prior("normal(0, 4)", class = "b")
)
```

```{r b1.general1-prime-model}
plan(multicore)
b1.general1_prime <- brm(formula = formula,
                data = ptb_data_ind, family = binomial(link = logit),
                prior = priors,
                iter = 3000, warmup = 1000, cores = 8, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b1.general1.prime")
summary(b1.general1_prime)
```

Interpreting the parameter estimates.

Arrange parameter summaries for both models.

```{r}
tibble(model = str_c("model ", letters[1:2]),
       fit   = c("b0.general1","b1.general1_prime")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  mutate(e_sd  = str_c(round(Estimate, digits = 2), " (", round(Est.Error, digits = 2), ")")) %>% 
  select(model, parameter, e_sd) %>% 
  pivot_wider(names_from = model, values_from = e_sd) %>% 
  knitr::kable()
  #flextable::flextable() %>% 
  #flextable::width(width = 1)
```

A coefficient plot will help us to get a sense of how the risk increases, decreases, or stays steady over time for the baseline logit hazard function (the time indicators).

```{r}
tibble(model = str_c("model ", letters[1:2]),
       fit   = c("b0.general1","b1.general1_prime")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  filter(str_detect(parameter, "d")) %>% 
  mutate(parameter = factor(str_remove(parameter, "b_"), 
                            levels = str_c("d", 15:6))) %>%
  
  ggplot(aes(x = Estimate, xmin = Q2.5, xmax = Q97.5, y = parameter)) +
  geom_pointrange(fatten = 2.5) +
  labs(x = "posterior (log-odds scale)",
       y = NULL) +
  theme(axis.text.y = element_text(hjust = 0),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank()) +
  facet_wrap(~ model, nrow = 1)
```

The risk of response occurrence increases until bin 10 (400 ms), stays steady for 160 ms, and then decreases somewhat.
On the hazard scale:

```{r}
tibble(model = str_c("model ", letters[1:2]),
       fit   = c("b0.general1","b1.general1_prime")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  filter(str_detect(parameter, "d")) %>% 
  mutate(parameter = factor(str_remove(parameter, "b_"), 
                            levels = str_c("d", 15:6))) %>%
  mutate_at(vars(Estimate:Q97.5), .funs = inv_logit_scaled) %>% # convert from logit to probabiliy metric
  
  ggplot(aes(x = Estimate, xmin = Q2.5, xmax = Q97.5, y = parameter)) +
  geom_pointrange(fatten = 2.5) +
  labs(x = "posterior (hazard scale)",
       y = NULL) +
  theme(axis.text.y = element_text(hjust = 0),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank()) +
  facet_wrap(~ model, nrow = 1)
```

Hazard of event occurrence increases at an increasing rate until 400 ms, then stays more or less constant until 520 ms, and then drops a bit.

A table with model a's estimates on three scales (logit, odds, hazard):

```{r}
fixef(b0.general1) %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
  mutate(`time period` = str_remove(predictor, "d") %>% as.double()) %>% 
  select(`time period`, predictor, Estimate) %>% 
  mutate(`fitted odds`   = exp(Estimate),
         `fitted hazard` = inv_logit_scaled(Estimate)) %>% 
  mutate_if(is.double, round, digits = 4) %>% 
  knitr::kable()
  #flextable::flextable() %>% 
  #flextable::width(width = 1)
```

Interpreting the dichotomous predictors con and incon.

Summary for con from model b:

```{r}
fixef(b1.general1_prime)["con",]
```

Taking the anti-log of the estimate gives us an odds ratio:

```{r}
fixef(b1.general1_prime)["con", 1] %>% exp()
```

Plot this conversion for the posterior distribution:

```{r}
as_draws_df(b1.general1_prime) %>% # 14 x 8000: b_d6 ... b_d15 b_con b_incon lprior lp__
  select(-lp__) %>%
  as_tibble() %>%
 transmute(`log-odds`     = b_con,
            `odds-ratio` = exp(b_con)) %>% 
  pivot_longer(everything()) %>% 
  mutate(name = factor(name, levels = c("log-odds", "odds-ratio"))) %>% 
  
  ggplot(aes(x = value, y = 0)) +
  stat_halfeye(.width = c(.5, .95), normalize = "panels") +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab("marginal posterior for con") +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ name, scales = "free")
```

In every bin, the estimated odds of response (button-press) occurrence are 1.66 times higher for congruent prime trials compared to neutral prime trials. 

To reframe the odds ratio in terms of the other group (i.e., con == 0), take the reciprocal.

```{r}
1 / exp(fixef(b1.general1_prime)[11, 1]) # 0.604
```

The estimated odds of response occurrence for neutral prime trials are approximately 60% of the odds for congruent prime trials

Make a similar plot for incon.

```{r}
as_draws_df(b1.general1_prime) %>% 
  transmute(`log-odds`     = b_incon,
            `odds-ratio` = exp(b_incon)) %>% 
  pivot_longer(everything()) %>% 
  mutate(name = factor(name, levels = c("log-odds", "odds-ratio"))) %>% 
  
  ggplot(aes(x = value, y = 0)) +
  stat_halfeye(.width = c(.5, .95), normalize = "panels") +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab("marginal posterior for incon") +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ name, scales = "free")
```

# fit simple cloglog models


## b0.general - intercepts only ##

# formula #

```{r b0gencloglog-formula}
formula_gen = bf(event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15)
#formula = bf(event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15 + con +incon)
```

# check the priors available #

```{r b0gencloglog-prior}
get_prior(formula_gen,
          data = ptb_data_ind, family = binomial(link=cloglog))
```

## visualise priors ##

here we would normally visualise priors of interest to make a judgment about what
would constitute weakly informative priors. 

```{r b0gencloglog-vis-priors}
visualize("normal(0, 0.5)", "normal(0, 1)", "normal(0, 2)", "normal(0,4)", 
          xlim = c(-8, 8))

```


```{r}
prior1 <- c(
  set_prior("normal(0, 4)", class = "b")
)
```

# run the first model : general, prior_0

```{r b0-cloglog-prior0-model}
plan(multicore)
b0gencloglog_pr0 <- brm(formula = formula_gen,
                data = ptb_data_ind, family = binomial(link = cloglog),
                prior = NULL,
                iter = 3000, warmup = 1000, cores = 4, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b0gencloglog_pr0") 
summary(b0gencloglog_pr0)
```

## take a look ##

```{r b0.general1-chains}
summary(b0gencloglog_pr0)
plot(b0gencloglog_pr0)
```

A table with model's estimates on two scales (cloglog, hazard):

```{r}
fixef(b0gencloglog_pr0) %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
  mutate(`time period` = str_remove(predictor, "d") %>% as.double()) %>% 
  select(`time period`, predictor, Estimate) %>% 
  mutate(`fitted hazard` = invcloglog(Estimate)) %>% 
  mutate_if(is.double, round, digits = 4) %>% 
  knitr::kable()
```

# run the second cloglog model : general, prior1

```{r b0-cloglog-prior1-model}
plan(multicore)
b0gencloglog_pr1 <- brm(formula = formula_gen,
                data = ptb_data_ind, family = binomial(link = cloglog),
                prior = prior1,
                iter = 3000, warmup = 1000, cores = 4, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b0gencloglog_pr1") 
summary(b0gencloglog_pr1)
```

Simulate prior predictive distr

```{r b0gencloglog_pr1_prior}
plan(multicore)
b0gencloglog_pr1_prior2 <- brm(formula = formula_gen,
                data = ptb_data_ind, family = binomial(link = cloglog),
                prior = prior1,
                iter = 3000, warmup = 1000, cores = 1, chains = 1,
                save_pars = save_pars(all=TRUE),
                sample_prior = "only",
                seed = 123,
                file = "models/b0gencloglog_pr1_prior2") 


```

```{r}
summary(b0gencloglog_pr1_prior2)

pp_check(b0gencloglog_pr1_prior2, type="error_hist")
pp_check(b0gencloglog_pr1_prior2, type="bars")


draws <- as_draws_df(b0gencloglog_pr1_prior2) # 500 observations x 15 vars
draws2 <- prior_draws(b0gencloglog_pr1_prior2, "b_d6")

# marginal posteriror for d6
draws %>% 
  pivot_longer(b_d6:b_d15) %>% 
  
  ggplot(aes(x = value, y = name, fill = after_stat(x > 0))) +
  stat_slab() +
  scale_fill_manual(values = c("blue3", "red3")) +
  labs(x = "marginal posterior",
       y = NULL) +
 theme(panel.grid = element_blank())


test <- posterior_predict(b0gencloglog_pr1_prior2)
test[1:10,1:10]
means <- rowMeans(test)
mean(means)
```

# Let's display fitted hazard and survivor functions for b0gencloglog_pr1_prior

First, we can create a table with the posterior means, ignoring uncertainty.

```{r}
invcloglog <- function(x) { return( 1-(exp(-1*exp(x))) )}
cloglog    <- function(x) { return( log(-1*log(1-x)) )}

tibble(time  = 6:15,
       alpha = fixef(b0gencloglog_pr1_prior2)[1:10, 1]) %>% 
  mutate(clh0 = alpha) %>% # cloglog-hazard
  mutate(h0 = invcloglog(clh0)) %>% 
  mutate(s0 = cumprod(1 - h0)) %>% 
  # this just simplifies the output
  mutate_if(is.double, round, digits = 4) %>% colMeans()
```

To make a plot, we go beyond posterior means and reintroduce the uncertainty in the model.


```{r}
nd <-
  crossing(period = 6:15) %>% 
  #mutate(condition = rep(c("Neutral","Congruent","Incongruent"),each=10),
  #       condition = factor(condition)) %>%
  mutate(d6  = if_else(period == 6, 1, 0),
         d7  = if_else(period == 7, 1, 0),
         d8  = if_else(period == 8, 1, 0),
         d9  = if_else(period == 9, 1, 0),
         d10 = if_else(period == 10, 1, 0),
         d11 = if_else(period == 11, 1, 0),
         d12 = if_else(period == 12, 1, 0),
         d13 = if_else(period == 13, 1, 0),
         d14 = if_else(period == 14, 1, 0),
         d15 = if_else(period == 15, 1, 0))

f <-
  fitted(b0gencloglog_pr1_prior2,
         newdata = nd,
         scale = "linear") %>% 
  data.frame() %>% 
  bind_cols(nd) 

f
```

Now make a plot.

```{r}
# cloglog(hazard)
p1 <-
  f %>% 
  
  ggplot(aes(x = period)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              linewidth = 0, alpha = 1/6) +
  geom_line(aes(y = Estimate)) +
  labs(subtitle = "fitted cloglog(hazard)",
       y = NULL) +
  coord_cartesian(ylim = c(-10, 10)) +
  theme(legend.background = element_rect(fill = "transparent"),
        legend.key = element_rect(color = "grey92"),
        legend.position = "inside",
        legend.position.inside = c(.1, .74))

# hazard
p2 <-
  f %>% 
  mutate_at(vars(Estimate, Q2.5, Q97.5), .funs = invcloglog) %>% 
  
  ggplot(aes(x = period)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              linewidth = 0, alpha = 1/6) +
  geom_line(aes(y = Estimate)) +
  labs(subtitle = "fitted hazard",
       y = NULL) +
  coord_cartesian(ylim = c(0, 1)) +
  theme(legend.position = "none")

# survival
p3 <-
  f %>% 
  mutate_at(vars(Estimate, Q2.5, Q97.5), .funs = invcloglog) %>% 
#  group_by(condition) %>% 
  mutate(s       = cumprod(1 - Estimate),
         s_lower = cumprod(1 - Q2.5),
         s_upper = cumprod(1 - Q97.5)) %>% 
  ungroup() %>%
  #select(period:d15, s:s_upper)
  
  ggplot(aes(x = period)) +
  geom_hline(yintercept = .5, color = "white") +
  #geom_segment(x = imls[1], xend = imls[1],
  #             y = -Inf, yend = .5,
  #             color = "white", linetype = 2) +
  #geom_segment(x = imls[2], xend = imls[2],
  #             y = -Inf, yend = .5,
  #             color = "white", linetype = 2) +
  geom_ribbon(aes(ymin = s_lower, ymax = s_upper),
              linewidth = 0, alpha = 1/6) +
  geom_line(aes(y = s)) + 
  scale_y_continuous(NULL, breaks = c(0, .5, 1)) +
  labs(subtitle = "fitted survival probability") +
  coord_cartesian(ylim = c(0, 1)) +
  theme(legend.position = "none")


```

```{r}
(p1 / p2 / p3 ) &
  scale_fill_viridis_d(NULL, option = "A", end = .6) &
  scale_color_viridis_d(NULL, option = "A", end = .6) &
  scale_x_continuous("Time bin rank", breaks = 6:15, limits = c(6, 15), labels=c(6:15*40)) &
  theme(panel.grid = element_blank())
```


#######
## take a look ##

```{r b0.general1-chains}
summary(b0gencloglog_pr1)
plot(b0gencloglog_pr1)
```

A table with model's estimates on two scales (cloglog, hazard):

```{r}
fixef(b0gencloglog_pr1) %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
  mutate(`time period` = str_remove(predictor, "d") %>% as.double()) %>% 
  select(`time period`, predictor, Estimate) %>% 
  mutate(`fitted hazard` = invcloglog(Estimate)) %>% 
  mutate_if(is.double, round, digits = 4) %>% 
  knitr::kable()
```

# same estimates (2 digits) between prior1 and NULL

# run the third cloglog model : general, prior2

```{r}
prior2 <- c(
  set_prior("normal(-2, 2)", class = "b")
)
```


```{r b0-cloglog-prior2-model}
plan(multicore)
b0gencloglog_pr2 <- brm(formula = formula_gen,
                data = ptb_data_ind, family = binomial(link = cloglog),
                prior = prior2,
                iter = 3000, warmup = 1000, cores = 4, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b0gencloglog_pr2") 
summary(b0gencloglog_pr2)
```

## take a look ##

```{r b0.general1-chains}
summary(b0gencloglog_pr2)
plot(b0gencloglog_pr2)
```

A table with model's estimates on two scales (cloglog, hazard):

```{r}
fixef(b0gencloglog_pr2) %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
  mutate(`time period` = str_remove(predictor, "d") %>% as.double()) %>% 
  select(`time period`, predictor, Estimate) %>% 
  mutate(`fitted hazard` = invcloglog(Estimate)) %>% 
  mutate_if(is.double, round, digits = 4) %>% 
  knitr::kable()
```


# run the fourth cloglog model : general, prior3

```{r}
#mu=-0.59, sigma = 1.26, alpha = -4.20. # flat prior for cloglog
prior3 <- c(
  set_prior("skew_normal(-0.59, 1.26, -4.20)", class = "b")
)
```


```{r b0-cloglog-prior3-model}
plan(multicore)
b0gencloglog_pr3 <- brm(formula = formula_gen,
                data = ptb_data_ind, family = binomial(link = cloglog),
                prior = prior3,
                iter = 3000, warmup = 1000, cores = 4, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b0gencloglog_pr3") 
summary(b0gencloglog_pr3)
```

## take a look ##

```{r b0.general1-chains}
summary(b0gencloglog_pr3)
plot(b0gencloglog_pr3)
get_prior(b0gencloglog_pr3)
```

A table with model's estimates on two scales (cloglog, hazard):

```{r}
fixef(b0gencloglog_pr3) %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
  mutate(`time period` = str_remove(predictor, "d") %>% as.double()) %>% 
  select(`time period`, predictor, Estimate) %>% 
  mutate(`fitted hazard` = invcloglog(Estimate)) %>% 
  mutate_if(is.double, round, digits = 4) %>% 
  knitr::kable()
```

# estimates are still similar... :)

Fit new models with PRIME info... and priors 0 to 4 (last has separate alpha and beta priors)

# formula #

```{r b0gencloglogPR-formula}
formula_genPR = bf(event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15 + con +incon)
```

# run the first cloglogPR model : generalPR, prior_0

```{r b0-cloglogPR-prior0-model}
plan(multicore)
b0gencloglogPR_pr0 <- brm(formula = formula_genPR,
                data = ptb_data_ind, family = binomial(link = cloglog),
                prior = NULL,
                iter = 3000, warmup = 1000, cores = 4, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b0gencloglogPR_pr0") 
summary(b0gencloglogPR_pr0)
```

## take a look ##

```{r b0.general1-chains}
summary(b0gencloglogPR_pr0)
plot(b0gencloglogPR_pr0)
```

A table with 2 model's estimates on two scales (cloglog, hazard):

```{r}
fixef(b0gencloglogPR_pr0) %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
#  mutate(`time period` = str_remove(predictor, "") %>% as.double()) %>% 
  select(predictor, Estimate) %>% 
  mutate(`fitted hazard` = invcloglog(Estimate),
         hr = exp(Estimate)) %>% 
  mutate_if(is.double, round, digits = 4) %>% 
  knitr::kable()
```


```{r}
tibble(model = str_c("model ", letters[1:2]),
       fit   = c("b0gencloglog_pr0","b0gencloglogPR_pr0")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  mutate(e_sd  = str_c(round(Estimate, digits = 2), " (", round(Est.Error, digits = 2), ")")) %>% 
  select(model, parameter, e_sd) %>% 
  pivot_wider(names_from = model, values_from = e_sd) %>% 
  knitr::kable()
  #flextable::flextable() %>% 
  #flextable::width(width = 1)
```

# run the second cloglogPR model : generalPR, prior1

```{r b0-cloglogPR-prior1-model}
plan(multicore)
b0gencloglogPR_pr1 <- brm(formula = formula_genPR,
                data = ptb_data_ind, family = binomial(link = cloglog),
                prior = prior1,
                iter = 3000, warmup = 1000, cores = 4, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b0gencloglogPR_pr1") 
summary(b0gencloglogPR_pr1)
```

## take a look ##

```{r b0.general1-chains}
summary(b0gencloglogPR_pr1)
plot(b0gencloglogPR_pr1)
```

A table with model's estimates on two scales (cloglog, hazard):

```{r}
fixef(b0gencloglogPR_pr1) %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
 # mutate(`time period` = str_remove(predictor, "d") %>% as.double()) %>% 
  select(predictor, Estimate) %>% 
  mutate(`fitted hazard` = invcloglog(Estimate),
         hr = exp(Estimate)) %>% 
  mutate_if(is.double, round, digits = 4) %>% 
  knitr::kable()
```

```{r}
tibble(model = str_c("model ", letters[1:2]),
       fit   = c("b0gencloglog_pr1","b0gencloglogPR_pr1")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  mutate(e_sd  = str_c(round(Estimate, digits = 2), " (", round(Est.Error, digits = 2), ")")) %>% 
  select(model, parameter, e_sd) %>% 
  pivot_wider(names_from = model, values_from = e_sd) %>% 
  knitr::kable()
  #flextable::flextable() %>% 
  #flextable::width(width = 1)
```


# run the third cloglogPR model : generalPR, prior2

```{r b0-cloglogPR-prior2-model}
plan(multicore)
b0gencloglogPR_pr2 <- brm(formula = formula_genPR,
                data = ptb_data_ind, family = binomial(link = cloglog),
                prior = prior2,
                iter = 3000, warmup = 1000, cores = 4, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b0gencloglogPR_pr2") 
summary(b0gencloglogPR_pr2)
```

## take a look ##

```{r b0.general1-chains}
summary(b0gencloglogPR_pr2)
plot(b0gencloglogPR_pr2)
```

A table with model's estimates on two scales (cloglog, hazard):

```{r}
fixef(b0gencloglogPR_pr2) %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
 # mutate(`time period` = str_remove(predictor, "d") %>% as.double()) %>% 
  select(predictor, Estimate) %>% 
  mutate(`fitted hazard` = invcloglog(Estimate),
         hr = exp(Estimate)) %>% 
  mutate_if(is.double, round, digits = 4) %>% 
  knitr::kable()
```

```{r}
tibble(model = str_c("model ", letters[1:2]),
       fit   = c("b0gencloglog_pr2","b0gencloglogPR_pr2")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  mutate(e_sd  = str_c(round(Estimate, digits = 2), " (", round(Est.Error, digits = 2), ")")) %>% 
  select(model, parameter, e_sd) %>% 
  pivot_wider(names_from = model, values_from = e_sd) %>% 
  knitr::kable()
```

```{r}
tibble(model = str_c("model ", letters[1:3]),
       fit   = c("b0gencloglogPR_pr0","b0gencloglogPR_pr1","b0gencloglogPR_pr2")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  mutate(e_sd  = str_c(round(Estimate, digits = 2), " (", round(Est.Error, digits = 2), ")")) %>% 
  select(model, parameter, e_sd) %>% 
  pivot_wider(names_from = model, values_from = e_sd) %>% 
  knitr::kable()
```

# run the fourth cloglogPR model : generalPR, prior3

```{r b0-cloglogPR-prior3-model}
plan(multicore)
b0gencloglogPR_pr3 <- brm(formula = formula_genPR,
                data = ptb_data_ind, family = binomial(link = cloglog),
                prior = prior3,
                iter = 3000, warmup = 1000, cores = 4, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b0gencloglogPR_pr3") 
summary(b0gencloglogPR_pr3)
```

## take a look ##

```{r b0.general1-chains}
summary(b0gencloglogPR_pr3)
plot(b0gencloglogPR_pr3)
```

A table with model's estimates on two scales (cloglog, hazard):

```{r}
fixef(b0gencloglogPR_pr3) %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
 # mutate(`time period` = str_remove(predictor, "d") %>% as.double()) %>% 
  select(predictor, Estimate) %>% 
  mutate(`fitted hazard` = invcloglog(Estimate),
         hr = exp(Estimate)) %>% 
  mutate_if(is.double, round, digits = 4) %>% 
  knitr::kable()
```

```{r}
tibble(model = str_c("model ", letters[1:2]),
       fit   = c("b0gencloglog_pr3","b0gencloglogPR_pr3")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  mutate(e_sd  = str_c(round(Estimate, digits = 2), " (", round(Est.Error, digits = 2), ")")) %>% 
  select(model, parameter, e_sd) %>% 
  pivot_wider(names_from = model, values_from = e_sd) %>% 
  knitr::kable()
```

```{r}
tibble(model = str_c("model ", letters[1:4]),
       fit   = c("b0gencloglogPR_pr0","b0gencloglogPR_pr1","b0gencloglogPR_pr2","b0gencloglogPR_pr3")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  mutate(e_sd  = str_c(round(Estimate, digits = 2), " (", round(Est.Error, digits = 2), ")")) %>% 
  select(model, parameter, e_sd) %>% 
  pivot_wider(names_from = model, values_from = e_sd) %>% 
  knitr::kable()
```


# run the fifth cloglogPR model : generalPR, prior4

```{r}
#mu=-0.59, sigma = 1.26, alpha = -4.20. # flat prior for cloglog
prior4 <- c(
  set_prior("skew_normal(-0.59, 1.26, -4.20)", class = "b"), # almost flat on p for  cloglog scale
  set_prior("skew_normal(-0.2, .7, -2.2)", class = "b", coef = "con"), # regularizing toward invcloglog(0)
  set_prior("skew_normal(-0.2, .7, -2.2)", class = "b", coef = "incon")
)
```

```{r b0-cloglogPR-prior4-model}
plan(multicore)
b0gencloglogPR_pr4 <- brm(formula = formula_genPR,
                data = ptb_data_ind, family = binomial(link = cloglog),
                prior = prior4,
                iter = 3000, warmup = 1000, cores = 4, chains = 4,
                save_pars = save_pars(all=TRUE),
                seed = 123,
                file = "models/b0gencloglogPR_pr4") 
summary(b0gencloglogPR_pr4)
```

## take a look ##

```{r b0.general1-chains}
summary(b0gencloglogPR_pr4)
plot(b0gencloglogPR_pr4)

get_prior(b0gencloglogPR_pr4)
prior_summary(b0gencloglogPR_pr4)
```

A table with model's estimates on two scales (cloglog, hazard):

```{r}
fixef(b0gencloglogPR_pr4) %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
 # mutate(`time period` = str_remove(predictor, "d") %>% as.double()) %>% 
  select(predictor, Estimate) %>% 
  mutate(`fitted hazard` = invcloglog(Estimate),
         hr = exp(Estimate)) %>% 
  mutate_if(is.double, round, digits = 4) %>% 
  knitr::kable()
```

Compare effect of priors on 9 models

```{r}
tibble(model = str_c("model ", letters[1:5]),
       fit   = c("b0gencloglogPR_pr0","b0gencloglogPR_pr1","b0gencloglogPR_pr2","b0gencloglogPR_pr3","b0gencloglogPR_pr4")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  mutate(e_sd  = str_c(round(Estimate, digits = 2), " (", round(Est.Error, digits = 2), ")")) %>% 
  select(model, parameter, e_sd) %>% 
  pivot_wider(names_from = model, values_from = e_sd) %>% 
  knitr::kable()
```

```{r}
tibble(model = str_c("model ", letters[1:4]),
       fit   = c("b0gencloglog_pr0","b0gencloglog_pr1","b0gencloglog_pr2","b0gencloglog_pr3")) %>% 
  mutate(f = map(fit, ~ get(.) %>% 
                   fixef() %>% 
                   data.frame() %>% 
                   rownames_to_column("parameter"))) %>% 
  unnest(f) %>% 
  mutate(e_sd  = str_c(round(Estimate, digits = 2), " (", round(Est.Error, digits = 2), ")")) %>% 
  select(model, parameter, e_sd) %>% 
  pivot_wider(names_from = model, values_from = e_sd) %>% 
  knitr::kable()
```

Type of prior has no effect here. 

## Compare models using information criteria

```{r}
log_lik(b0gencloglogPR_pr4) %>% # 8000 x 12840 pointwise log-likelihood samples
  str()
```

Calculate LL and deviance for each sample.

```{r}
ll <-
  b0gencloglogPR_pr4 %>%
  log_lik() %>%
  as_tibble(.name_repair = ~ str_c("c", 1:12840)) %>%
  mutate(ll = rowSums(.)) %>% 
  mutate(deviance = -2 * ll) %>% 
  select(ll, deviance, everything())

ll
```

```{r}
ll %>%
  pivot_longer(ll:deviance) %>% 
  mutate(name = factor(name, levels = c("ll", "deviance"))) %>% 
  
  ggplot(aes(x = value, y = 0)) +
  stat_halfeye(point_interval = median_qi, .width = .95, normalize = "panels") +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(NULL) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ name, scales = "free")
```

For all three models:

```{r}
ll <-
  tibble(model = str_c("model ", letters[1:3]),
         name  = c("b0gencloglogPR_pr2","b0gencloglogPR_pr3", "b0gencloglogPR_pr4")) %>% 
  mutate(fit = map(name, get)) %>% 
  mutate(ll = map(fit, ~log_lik(.) %>% data.frame() %>% transmute(ll = rowSums(.)))) %>% 
  select(-fit) %>% 
  unnest(ll) %>% 
  mutate(deviance = -2 * ll)

ll %>% 
  glimpse()
```


```{r}
ll %>%
  pivot_longer(ll:deviance,
               names_to = "statistic") %>% 
  mutate(statistic = factor(statistic, levels = c("ll", "deviance"))) %>% 
  
  ggplot(aes(x = value, y = model)) +
  stat_halfeye(point_interval = median_qi, .width = .95, normalize = "panels") +
  labs(x = NULL,
       y = NULL) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ statistic, scales = "free_x")
```

Using WAIC and LOO for comparing nonnested models.

```{r}
b0gencloglogPR_pr2  <- add_criterion(b0gencloglogPR_pr2, c("loo", "waic"))
b0gencloglogPR_pr3  <- add_criterion(b0gencloglogPR_pr3, c("loo", "waic"))
b0gencloglogPR_pr4  <- add_criterion(b0gencloglogPR_pr4, c("loo", "waic"))
```

Compare all three models:

```{r}
loo_compare(b0gencloglogPR_pr2, b0gencloglogPR_pr3, b0gencloglogPR_pr4, criterion = "loo") %>% print(simplify = F)
loo_compare(b0gencloglogPR_pr2, b0gencloglogPR_pr3, b0gencloglogPR_pr4, criterion = "waic") %>% print(simplify = F)
```

```{r}
model_weights(b0gencloglogPR_pr2, b0gencloglogPR_pr3, b0gencloglogPR_pr4, weights = "loo") %>% round(digits = 3)

model_weights(b0gencloglogPR_pr2, b0gencloglogPR_pr3, b0gencloglogPR_pr4, weights = "waic") %>% round(digits = 3)

model_weights(b0gencloglogPR_pr2, b0gencloglogPR_pr3, b0gencloglogPR_pr4, weights = "stacking") %>% round(digits = 3)
```

####### make plot of priors ################

```{r}
logistic <- function(x) { return( 1/(1+exp(-1*x)) )}
logit    <- function(x) { return( log(x/(1-x)) )}
invcloglog <- function(x) { return( 1-(exp(-1*exp(x))) )}
cloglog    <- function(x) { return( log(-1*log(1-x)) )}

pr1 <- tibble(prior = rnorm(1e6, mean = 0, sd = 4)) %>%  
  mutate(p = logistic(prior)) %>% 
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-13, y=60000, label="N(0,4)",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l1 <- tibble(log_odds = rnorm(1e6, mean = 0, sd = 4)) %>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  ggtitle("logistic") +
  theme(panel.grid = element_blank())

c1 <- tibble(cloglog_prob = rnorm(1e6, mean = 0, sd = 4)) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  ggtitle("inverse cloglog")+
  theme(panel.grid = element_blank())


pr2 <- tibble(prior = rnorm(1e6, mean = 0, sd = 2)) %>%  
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-6, y=60000, label="N(0,2)",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l2 <- tibble(log_odds = rnorm(1e6, mean = 0, sd = 2)) %>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

c2 <- tibble(cloglog_prob = rnorm(1e6, mean = 0, sd = 2)) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

# flat prior for logistic
pr3 <- tibble(prior = rt(1e6, df = 7.61)* 1.57) %>%  
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-4, y=100000, label="t(7.61)*1.57",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l3 <- tibble(log_odds = rt(1e6, df = 7.61)* 1.57) %>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

c3 <- tibble(cloglog_prob = rt(1e6, df = 7.61)* 1.57) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
  #geom_histogram(bins = 50) +
  #scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

# prior to .5
pr4 <- tibble(prior = rnorm(1e6, mean = 0, sd = 1))%>%  
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-3, y=60000, label="N(0,1)",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l4 <- tibble(log_odds = rnorm(1e6, mean = 0, sd = 1))%>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  geom_vline(xintercept=logistic(0), color="red") +
  theme(panel.grid = element_blank())

c4 <- tibble(cloglog_prob = rnorm(1e6, mean = 0, sd = 1)) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
 # geom_histogram(bins = 50) +
#  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

# flat on cloglog
pr5 <- tibble(prior = rskew_normal(1e6, mu=-0.59, sigma = 1.26, alpha = -4.20)) %>%  
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-3, y=60000, label="skew_N(-0.59,1.26,-4.20)",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l5 <- tibble(log_odds = rskew_normal(1e6, mu=-0.59, sigma = 1.26, alpha = -4.20))%>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
#  geom_histogram(bins = 50) +
#  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

c5 <- tibble(cloglog_prob = rskew_normal(1e6, mu=-0.59, sigma = 1.26, alpha = -4.20)) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())


# regu to invcloglog(0)
pr6 <- tibble(prior = rskew_normal(1e6, mu=-0.2, sigma = .7, alpha = -2.20)) %>%  
  ggplot(aes(x = prior)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  annotate(geom="text", x=-1, y=60000, label="skew_N(-0.2,.7,-2.20)",
              color="red", size=6) +
  theme(panel.grid = element_blank())

l6 <- tibble(log_odds = rskew_normal(1e6, mu=-0.2, sigma = .7, alpha = -2.20))%>%  
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
 # geom_histogram(bins = 50) +
#  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

c6 <- tibble(cloglog_prob = rskew_normal(1e6, mu=-0.2, sigma = .7, alpha = -2.20)) %>% 
  mutate(p = invcloglog(cloglog_prob)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept=invcloglog(0), color = "red") +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())



(l1 + pr1 + c1) / (l2 + pr2 + c2) / (l3 + pr3 + c3) / (l4 + pr4 + c4)/ (l5 + pr5 + c5) / (l6 + pr6 + c6)

```


```{r}
ggsave("figures/plot_of_priors.png", width=9, height=10,dpi=300)
```

The log-odds Normal(0,1) gently regularizes p towards .5, but still allows for stronger values. This might be a good prior to use for the beta parameters. 



######################################################

## Intermezzo: priors

Simulate from Normal(0,4) and transform the draws back into the probability metric.

```{r}
set.seed(11)
#log_odds <- function(p) {
##  log(p / (1 - p))
#}
#odds <- function(p) {
#  p/(1-p)
#}
#cloglog <- function(p){
#  log(-log(1-p))
#}

#inv_cloglog <- function(p){
#  1-exp(-exp(p))
#}
# logit
tibble(log_odds = rnorm(1e6, mean = 0, sd = 1)) %>% # N(0,1) regularized gently toward .5
  mutate(p = logistic(log_odds)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

#cloglog
tibble(clog_log = rnorm(1e6, mean = -1.4, sd = 1.2)) %>%  
  # good intercept prior : -1, 1.1/-1.4,1/-1.4,1.3/-1.4,1.2
  # good beta prior : 
  mutate(p = invcloglog(clog_log)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

# check other distributions
library(sn)
#cloglog. uniform
tibble(clog_log = runif(1e6, min = -4, max = 2)) %>%  
  mutate(p = invcloglog(clog_log)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())
# cloglog skew normal
tibble(clog_log = rsn(1e6, xi = 0.5, omega=1, alpha =-2)) %>%  # 0.5, 1, -2 /beta.  SN
  mutate(p = invcloglog(clog_log)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())


# cloglog skew normal
tibble(clog_log = rskew_normal(1e6, mu = -0.2, sigma=.7, alpha =-2.2)) %>%  # -0.3, 1, -2 /-0.2,.7,-2.2beta !!!!!!!
  mutate(p = invcloglog(clog_log)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())


# generate draws from sn
dat <- 
  tibble(c1 = rsn(1e6, 0.5, 1,-2), # xi omega alpha
         c2 = rskew_normal(1e6,-0.2,.7,-2.2)) %>% # mu sigma alpha
  mutate(p1 = invcloglog(c1),
         p2 = invcloglog(c2)) 

plot(density(dat$c2))
plot(density(dat$p2))


```

N(0,4) make no sense for logit-hazard models.




Compare three standard deviations.

```{r}
set.seed(11)

tibble(sd = c(2, 1.5, 1)) %>% 
  mutate(log_odds = map(sd, ~rnorm(1e6, mean = 0, sd = .))) %>% 
  unnest(log_odds) %>% 
  mutate(sd = str_c("sd = ", sd),
         p  = inv_logit_scaled(log_odds)) %>% 

  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ sd)

tibble(sd = c(1,1.1,1.2,1.3,1.4,1.5)) %>% 
  mutate(clog_log = map(sd, ~rnorm(1e6, mean = -1, sd = .))) %>% # 1.1 good for intercept intercept
  unnest(clog_log) %>% 
  mutate(sd = str_c("sd = ", sd),
         p  = invcloglog(clog_log)) %>% 

  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ sd)


```

The log-odds Normal(0,1) gently regularizes p towards .5, but still allows for stronger values. This might be a good prior to use for the beta parameters. 

```{r}
tibble(omega = c(1,1.1,1.2,1.3,1.4,1.5)) %>% 
  mutate(clog_log = map(omega, ~rsn(1e6, -1, omega = ., alpha = 2))) %>% 
  unnest(clog_log) %>% 
  mutate(omega = str_c("omega = ", omega),
         p  = invcloglog(clog_log)) %>% 

  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ omega)

tibble(alpha = c(-8,-7,-6, -5,-4,-3)) %>% 
  mutate(clog_log = map(alpha, ~rsn(1e6, -0.5, sigma = .95, alpha = .))) %>% #!!!!!!! -0.5, .95,-4
  unnest(clog_log) %>% 
  mutate(alpah = str_c("alpha = ", alpha),
         p  = invcloglog(clog_log)) %>% 

  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ alpha)


tibble(alpha = c(-2, -1, 0, 1, 2),
       sigma = c(1,2,3,4,5)) %>% 
  mutate(clog_log = map2(sigma, alpha, ~rsn(1e6, -1, sigma = ., alpha = .))) %>% 
  unnest(clog_log) %>% 
  mutate(alpha = str_c("alpha = ", alpha),
         sigma = str_c("sigma = ", sigma)
         p  = invcloglog(clog_log)) %>% 

  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank()) +
  facet_grid(vars(alpha), vars(sigma))

```






The alpha parameters tend to drift toward the lower end of the probability range in general (i.e., they are typically below .5 in hazard space, also for RT studies). The log-odds Normal(0, 1.5) prior is nearly flat in probability space, but it does still push the mass away from the boundaries.

Solomon Kurz proposes to simulate a large number of draws from the Uniform(0,1) distribution, convert those draws to the log-odds metric, and fit a Student's t model, if we want to stay within the Student-t familiy of priors, of which the normal is a special case (to gain a sense of what prior values would approximate a uniform distriubution on the probability scale).

```{r}
set.seed(11)

# generate draws from U(0,1)
dat <- 
  tibble(p = runif(1e5, 0, 1)) %>% 
  mutate(g = logit(p),
         c = cloglog(p)) 
# display
dat %>%   
  ggplot(aes(x = c)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

plot(density(dat$c))

# fit models
fit11.11 <-
  brm(data = dat,
      family = student,
      g ~ 1,
      chains = 4, cores = 4,
      file = "models/fit11.11")


fit11.11b <-
  brm(data = dat,
      family = skew_normal(),
      c ~ 1,
      chains = 4, cores = 4,
      file = "models/fit11.11b")

fit11.11b2 <-
  brm(data = dat,
      family = student(),
      c ~ 1,
      chains = 4, cores = 4,
      file = "models/fit11.11b2")

```

```{r}
print(fit11.11)
print(fit11.11b)
print(fit11.11b2)


pp_check(fit11.11b)
```

Now we can reverse the process. Hereâ€™s what it would look like if we simulated from the Student  
t-distribution based on those posterior means and then converted the results into the probability metric.

```{r}
set.seed(11)
# logit
tibble(g = rt(1e6, df = 7.61)* 1.57) %>% # simulate from student t
  mutate(p = inv_logit_scaled(g)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())


library(extraDistr)
# cloglog
tibble(g = rlst(1e6, df = 5.98, mu=-0.45 , sigma= 1.05)) %>% # simulate from student t
  mutate(p = invcloglog(g)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())



# cloglog
library(sn)

tibble(c = rskew_normal(1e8, mu=-0.59, sigma = 1.26, alpha = -4.20) ) %>% # simulate from skew-normal #distribution !!!!!!!! for intercept 
#  !!!!!!!!!

#tibble(c = rsn(1e6, xi=-1, omega = 1, alpha = -2) ) %>% # simulate from skew-normal distribution
 
   mutate(p = invcloglog(c)) %>% 
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

# generate draws from sn
dat <- 
  tibble(c1 = rsn(1e5, -1, 1,-1),
         c2 = rskew_normal(1e5,-0.59,1.26,-4.2)) %>% # use as prior for cloglog intercept !!
  mutate(p1 = invcloglog(c1),
         p2 = invcloglog(c2)) 

plot(density(dat$c2))
plot(density(dat$p2))


# display
dat %>%   
  ggplot(aes(x = p1)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())

dat %>%   
  ggplot(aes(x = p2)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())
```

Check code from Alexis. https://stats.stackexchange.com/questions/367184/simulation-discrete-time-hazard-model

```{r}
N <- 12 # trials
T = 20 # censoring time

ID <- 1:N
Data <- data.frame(ID)

# Create conditioning variables (e.g., two dichotomous vars here, but
# these could be whatever number and kind), and bind these to your 
# data set
var1 <- c(rep(0,(N/2)),rep(1,N/2))
var2 <- c(rep(0,(N/4)),rep(1,(N/2)),rep(0,(N/4)))
Data <- cbind(Data,var1,var2)

# set up person-period structure
expand <- function(x,t) {
  data <- x[rep(1:length(x[,1]), each = t), ]
  rownames(data) <- NULL
  return(data)
  }

 Data <- expand(Data, T)
 Data$period <- rep(1:T,N)
  
 for (t in 1:T) {
       varname <- paste("t",t,sep="")
       Data[,varname] <- as.integer(0 + Data$period == t)
   }
```

Prepare effect of time on discrete-time hazard function

Based on your above model assumptions about how â„Žð‘¡ relates to time:

```{r}
#i. Constant baseline hazard:
# for a nominal hazard of 0.1:
conslogit   <- logit(0.1)   # logit(.1)   = -2.1972246
conscloglog <- cloglog(0.1)

#ii. Baseline hazard as a linear function of time

# for a linear effect of time on hazard of 0.05 per 1-unit increase in t:
linearcloglog   <- cloglog(invcloglog(0) + 0.05)

#iii. Baseline hazard as a fully discrete function of time
# for a fully discrete time effect on hazard (no. of discrete values
# should equal T; here there are 20):
discretehazards <- c(0.01, 0.01, 0.06, 0.20, 0.27, 0.37, 0.47, 0.50, 0.51, 0.52, 0.66, 0.76, 0.86, 0.96, 0.03, 0.15, 0.05, 0.11, 0.08, 0.14)
discretecloglog   <- cloglog(discretehazards)

```

Prepare effects of conditioning variables on â„Žð‘¡

```{r}
# for a nominal effect of var1 of 0.06 increase in hazard:
var1cloglog   <- cloglog(invcloglog(0) + 0.06)
#
# for a nominal hazard effect of var2 of 0.04:
var2cloglog   <- cloglog(invcloglog(0) + 0.04)

```

```{r}
#3. Simulate your discrete-time survival data
head(Data,n=30)
tail(Data,n=30)
# Example for baseline fully discrete effect of time:
for (t in 1:T) {
  Data$hcloglog[Data$period==t] <- invcloglog(discretecloglog[t])
  }
 

# Example for conditional logit hazard model with constant effect of time:
# (The [Data$period==t] on the conditioning variables are probably only
# necessary if your conditioning variables are *time varying*: if the 
# values of var1 or var2 were to change over time *within individuals*.)
for (t in 1:T) {
  Data$hcloglog2[Data$period==t] <- invcloglog(discretecloglog[t] + var1cloglog*Data$var1[Data$period==t] + var2cloglog*Data$var2[Data$period==t])
  }
```

###### Simulate data, and fit a model for parameter recovery




##############
Fit a new model with separate priors for alpha and beta parameters.

```{r}
plan(multicore)
b1.general1_prime_prior <-
  brm(data = ptb_data_ind,
      family = binomial,
      event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15 + con +incon,
      prior = c(prior(student_t(7.61, 0, 1.57), class = b), 
                prior(normal(0, 1), class = b, coef = con), 
                prior(normal(0, 1), class = b, coef = incon)),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      save_pars = save_pars(all=TRUE),
      seed = 11,
      file = "models/b1.general1_prime_prior")
```

```{r}
print(b1.general1_prime_prior)
print(b1.general1_prime)
```

Extract estimates and odds ratios for con and incon.

```{r}
fixef(b1.general1_prime_prior)[11:12, ] %>% 
  data.frame() %>% 
  rownames_to_column("predictor") %>% 
  mutate(`odds ratio` = exp(Estimate)) %>% 
  select(predictor, Estimate, `odds ratio`) %>% 
  mutate_if(is.double, round, digits = 3)
```






Perhaps we can use a similar strategy for hazard models for RT data, as experience suggests that hazard typically stays below .6 in empirical RT data: simulate a large number of draws from various beta(x,y) distributions, convert those draws to the log-odds metric, and fit a skew-normal or skew-t distribution:

```{r vis-beta-priors}
visualize("beta(1,2)","beta(1,3)","beta(1,4)", 
          xlim = c(0, 1))

```

```{r}
set.seed(11)

dat <- 
  tibble(p = rbeta(1e5, 1, 4)) %>% 
  mutate(g = log_odds(p)) 

plot(density(dat$g))

fit11.12 <-
  brm(data = dat,
      family = skew_normal(),
      g ~ 1,
      chains = 4, cores = 4,
      file = "models/fit11.12")
```

```{r}
print(fit11.12)
```

Reverse the process:

```{r}
set.seed(11)
library(sn)
tibble(g = rsn(1e6, xi=-1.85, omega = 1.37, alpha = -2.70) ) %>% # skew-normal distribution
  mutate(p = inv_logit_scaled(g)) %>% 
  
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())
```

Density is too low for p >  0.2...

The skew-t distribution is not available directly in stan, so let's try beta(1,3):

```{r}
set.seed(11)

dat <- 
  tibble(p = rbeta(1e5, 1, 3)) %>% 
  mutate(g = log_odds(p)) 

plot(density(dat$g))

fit11.13 <-
  brm(data = dat,
      family = skew_normal(),
      g ~ 1,
      chains = 4, cores = 4,
      file = "models/fit11.13")
```

```{r}
print(fit11.13)
```

Reverse the process:

```{r}
set.seed(11)
library(sn)
tibble(g = rsn(1e6, xi=-1.51, omega = 1.42, alpha = -2.36) ) %>% # skew-normal distribution
  mutate(p = inv_logit_scaled(g)) %>% 
  
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())
```

Still not good. Try beta(1,2)

```{r}
set.seed(11)

dat <- 
  tibble(p = rbeta(1e5, 1, 2)) %>% 
  mutate(g = log_odds(p)) 
plot(density(dat$p))
plot(density(dat$g))

fit11.14 <-
  brm(data = dat,
      family = skew_normal(),
      g ~ 1,
      chains = 4, cores = 4,
      file = "models/fit11.14")
```

```{r}
print(fit11.14)
```

Reverse the process:

```{r}
set.seed(11)
library(sn)
tibble(g = rsn(1e6, xi=-1.01, omega = 1.50, alpha = -1.83) ) %>% # skew-normal distribution
  mutate(p = inv_logit_scaled(g)) %>% 
  
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())
```

This looks quite good actually (for the alpha parameters in hazard models of RT data...).

Play around manually with alpha parameter:

```{r}
set.seed(11)
library(sn)
tibble(g = rsn(1e6, xi=-1, omega = 1.5, alpha = -0.1) ) %>% # skew-normal distribution
  mutate(p = inv_logit_scaled(g)) %>% 
  
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())
```

This looks even better...

Play with omega:

```{r}
set.seed(11)
library(sn)
tibble(g = rsn(1e6, xi=-1, omega = 1.1, alpha = -0.1) ) %>% # skew-normal distribution
  mutate(p = inv_logit_scaled(g)) %>% 
  
  ggplot(aes(x = p)) +
  geom_histogram(bins = 50) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())
```

This looks the best: prior density from 0 to 1, but more for p values below .6.

TODO: apply new prior for alpha's and compare estimates.

# end of intermezzo on priors


## Compare models using information criteria

```{r}
log_lik(b0.general1) %>% # 8000 x 12840 pointwise log-likelihood samples
  str()
```

Calculate LL and deviance for each sample.

```{r}
ll <-
  b0.general1 %>%
  log_lik() %>%
  as_tibble(.name_repair = ~ str_c("c", 1:12840)) %>%
  mutate(ll = rowSums(.)) %>% 
  mutate(deviance = -2 * ll) %>% 
  select(ll, deviance, everything())

ll
```

```{r}
ll %>%
  pivot_longer(ll:deviance) %>% 
  mutate(name = factor(name, levels = c("ll", "deviance"))) %>% 
  
  ggplot(aes(x = value, y = 0)) +
  stat_halfeye(point_interval = median_qi, .width = .95, normalize = "panels") +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(NULL) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ name, scales = "free")
```

For all three models:

```{r}
ll <-
  tibble(model = str_c("model ", letters[1:3]),
         name  = c("b0.general1","b1.general1_prime", "b1.general1_prime_prior")) %>% 
  mutate(fit = map(name, get)) %>% 
  mutate(ll = map(fit, ~log_lik(.) %>% data.frame() %>% transmute(ll = rowSums(.)))) %>% 
  select(-fit) %>% 
  unnest(ll) %>% 
  mutate(deviance = -2 * ll)

ll %>% 
  glimpse()
```


```{r}
ll %>%
  pivot_longer(ll:deviance,
               names_to = "statistic") %>% 
  mutate(statistic = factor(statistic, levels = c("ll", "deviance"))) %>% 
  
  ggplot(aes(x = value, y = model)) +
  stat_halfeye(point_interval = median_qi, .width = .95, normalize = "panels") +
  labs(x = NULL,
       y = NULL) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ statistic, scales = "free_x")
```

Using WAIC and LOO for comparing nonnested models.

```{r}
b0.general1  <- add_criterion(b0.general1, c("loo", "waic"))
b1.general1_prime  <- add_criterion(b1.general1_prime, c("loo", "waic"))
b1.general1_prime_prior  <- add_criterion(b1.general1_prime_prior, c("loo", "waic"))
```

Compare models a and b:

```{r}
loo_compare(b0.general1, b1.general1_prime, criterion = "loo") %>% print(simplify = F)
loo_compare(b0.general1, b1.general1_prime, criterion = "waic") %>% print(simplify = F)
```

Compare all three models:

```{r}
loo_compare(b0.general1, b1.general1_prime, b1.general1_prime_prior, criterion = "loo") %>% print(simplify = F)
loo_compare(b0.general1, b1.general1_prime, b1.general1_prime_prior, criterion = "waic") %>% print(simplify = F)
```

```{r}
model_weights(b0.general1, b1.general1_prime, b1.general1_prime_prior, weights = "loo") %>% round(digits = 3)

model_weights(b0.general1, b1.general1_prime, b1.general1_prime_prior, weights = "waic") %>% round(digits = 3)

model_weights(b0.general1, b1.general1_prime, b1.general1_prime_prior, weights = "stacking") %>% round(digits = 3)
```

# Extending the discrete-time hazard model.

## Alternative specifications for the effect of TIME

The use of a completely general specification for the effect of TIME is an analytic decision.

Count right-censored trials

```{r}
ptb_data_ind %>% 
  group_by(trial) %>% 
  arrange(desc(period)) %>% 
  slice(1) %>%
  ungroup() %>% 
  count(event) %>% 
  mutate(percent = 100 * n / sum(n))
```

```{r}
head(ptb_data_ind)
# change name for trials

plan(multicore)


# constant
b2.constant <-
  brm(data = ptb_data_ind,
      family = binomial,
      event | trials(1) ~ 1,
      prior(normal(0, 4), class = Intercept),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b2.constant")

# linear
b2.linear <-
  brm(data = ptb_data_ind,
      family = binomial,
      event | trials(1) ~ 0 + Intercept + period,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b2.linear")

# quadratic
b2.quad <-
  brm(data = ptb_data_ind,
      family = binomial,
      event | trials(1) ~ 0 + Intercept + period + I(period^2),
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b2.quad")

# cubic
b2.cubic <-
  brm(data = ptb_data_ind,
      family = binomial,
      event | trials(1) ~ 0 + Intercept + period + I(period^2) + I(period^3),
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b2.cubic")

# fourth order
# b2.quartic4 <-
#   brm(data = ptb_data_ind,
#       family = binomial,
#       event | trials(1) ~ 0 + Intercept + period + I(period^2) + I(period^3) + I(period^4),
#       prior(normal(0, 3), class = b),
#       chains = 4, cores = 8, iter = 5000, warmup = 1000,
#       control = list(max_treedepth = 14),
#       seed = 12,
#       file = "models/b2.quartic4")
# 
# # fifth order
# b2.quintic <-
#   brm(data = ptb_data_ind,
#       family = binomial,
#       event | trials(1) ~ 0 + Intercept + period + I(period^2) + I(period^3) + I(period^4) + I(period^5),
#       prior(normal(0, 4), class = b),
#       chains = 4, cores = 8, iter = 3000, warmup = 1000,
#       control = list(max_treedepth = 14),
#       seed = 12,
#       init = 0,
#       file = "models/b2.quintic")

# general
b2.general <-
  brm(data = ptb_data_ind,
      family = binomial,
      event | trials(1) ~ 0 + d6 + d7 + d8 + d9+ d10 + d11 + d12 + d13 + d14 + d15,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b2.general")

# general with `factor(period)`
b2.factor <-
  brm(data = ptb_data_ind,
      family = binomial,
      event | trials(1) ~ 0 + period_factor,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b2.factor")
```

check fits

```{r}
summary(b2.constant)
print(b2.linear)
print(b2.quad)
print(b2.cubic)
#print(b2.quartic) # Parts of the model have not converged. Increase iterations / stronger priors...
#print(b2.quintic) # Divergent transitions (increase adapt_delta above 0.8) + parts not converged...
print(b2.general)
print(b2.factor)
```


Inspect hazard functions

```{r}
p2 <- plot(conditional_effects(b2.linear), plot = F)[[1]] + ggtitle("linear")
p3 <- plot(conditional_effects(b2.quad), plot = F)[[1]] + ggtitle("quadratic")
p4 <- plot(conditional_effects(b2.cubic), plot = F)[[1]] + ggtitle("cubic")
#p5 <- plot(conditional_effects(b2.quartic3), plot = F)[[1]] + ggtitle("fourth order")
#p6 <- plot(conditional_effects(b2.quintic), plot = F)[[1]] + ggtitle("fifth order")
p7 <- plot(conditional_effects(b2.factor), 
           cat_args = list(size = 3/2), 
           plot = F)[[1]] + ggtitle("general")

p1 <-
  tibble(period = 6:15) %>% 
  ggplot(aes(x = period)) +
  geom_ribbon(aes(ymin = fixef(b2.constant)[, 3] %>% inv_logit_scaled(),
                  ymax = fixef(b2.constant)[, 4] %>% inv_logit_scaled()),
              alpha = 1/5) +
  geom_line(aes(y = fixef(b2.constant)[, 1] %>% inv_logit_scaled()),
            linewidth = 1, color = "blue1") +
  ggtitle("constant") +
  ylab("event | trials(1)")


library(patchwork)

(((p1 + p2 + p3 + p4) & scale_x_continuous(breaks = 6:15)) + p7) &
  coord_cartesian(ylim = c(0, 1)) &
  theme(panel.grid = element_blank())
```

```{r}
b2.constant <- add_criterion(b2.constant, criterion = c("loo", "waic"))
b2.linear   <- add_criterion(b2.linear,   criterion = c("loo", "waic"))
b2.quad     <- add_criterion(b2.quad,     criterion = c("loo", "waic"))
b2.cubic    <- add_criterion(b2.cubic,    criterion = c("loo", "waic"))
b2.general  <- add_criterion(b2.general,  criterion = c("loo", "waic"))
b2.factor   <- add_criterion(b2.factor,   criterion = c("loo", "waic"))
```

Compare dummy and factor models

```{r}
loo_compare(b2.general, b2.factor, criterion = "loo") %>% print(simplify = F)
loo_compare(b2.general, b2.factor, criterion = "waic") %>% print(simplify = F)
```

Compare polynomial specifications with general

```{r}
loo_compare(b2.constant, b2.linear, b2.quad, b2.cubic, b2.general, criterion = "loo") %>% 
  print(simplify = F)
loo_compare(b2.constant, b2.linear, b2.quad, b2.cubic, b2.general, criterion = "waic") %>% 
  print(simplify = F)
```

Model weights:

```{r}
model_weights(b2.constant, b2.linear, b2.quad, b2.cubic, b2.general, weights = "loo") %>% 
  round(digits = 3)
model_weights(b2.constant, b2.linear, b2.quad, b2.cubic, b2.general, weights = "waic") %>% 
  round(digits = 3)
model_weights(b2.constant, b2.linear, b2.quad, b2.cubic, b2.general, weights = "stacking") %>% 
  round(digits = 3)
```


Compare model pairs

```{r}
# the constant and linear models
l1 <- loo_compare(b2.constant, b2.linear, criterion = "loo")

# the linear and quadratic models
l2 <- loo_compare(b2.linear, b2.quad, criterion = "loo")

# the quadratic and general models
l3 <- loo_compare(b2.quad, b2.general, criterion = "loo")

l1 %>% print(simplify = F)
l2 %>% print(simplify = F)
l3 %>% print(simplify = F)
```

If we presume the LOO differences follow a normal distribution, we can use their point estimates and standard errors to plot those distributions using simulated data from good old rnorm().

```{r}
library(tidybayes)

n <- 1e6
models <- c("linear - constant", "quadratic - linear", "quadratic - general")
set.seed(12)

# wrangle
tibble(loo_difference = c(rnorm(n, mean = l1[2, 1] * -2, sd = l1[2, 2] * 2),
                          rnorm(n, mean = l2[2, 1] * -2, sd = l2[2, 2] * 2),
                          rnorm(n, mean = l3[2, 1] * -2, sd = l3[2, 2] * 2))) %>% 
  mutate(models = factor(rep(models, each = n),
                         levels = models)) %>% 
  
  # plot!
  ggplot(aes(x = loo_difference, y = 0)) +
  stat_halfeye(.width = c(.5, .95), normalize = "panels") +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "LOO-difference simulations based on 1,000,000 draws",
       x = "difference distribution") +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ models, scales = "free")
```

The LOO difference for the linear and constant models is decisive. 

The difference for the quadratic and linear models is fairly large on the information-criteria scale, and the uncertainty in that distribution is fairly small relative to its location (i.e., its mean), which leads to the conclusion that the quadratic is better compared to the linear. 

The comparison between the quadratic and the general produced a simulation with a modest location and rather large uncertainty relative to the magnitude of that location. All in all, â€œall signs point to the superiority of the quadratic specification, which fits nearly as well as the general mode, but with fewer parametersâ€ (p. 416).

Compare cubic and quadratic

```{r}
loo_compare(b2.quad, b2.cubic, criterion = "loo") %>% print(simplify = F)
loo_compare(b2.quad, b2.cubic, criterion = "waic") %>% print(simplify = F)
```

the cubic model has a slightly lower LOO and WAIC estimate compared to the quadratic. However, the standard errors for the formal difference score are about twice the size of that difference and the absolute magnitude of the difference is rather small to begin with. 
Hereâ€™s what it looks like if we compare them using LOO weights, WAIC weights, and stacking weights.

```{r}
model_weights(b2.quad, b2.cubic, weights = "loo") %>% round(digits = 3)
model_weights(b2.quad, b2.cubic, weights = "waic") %>% round(digits = 3)
model_weights(b2.quad, b2.cubic, weights = "stacking") %>% round(digits = 3)
```

Two guidelines for selecting among alternative specifications:

If a smooth specification works nearly as well as the completely general one, appreciably better than all simpler ones, and no worse than all more complex ones, consider adopting it.
If no smooth specifications meet these criteria, retain the completely general specification.



Model averaging:

Before moving on, we might point out that our Bayesian brms-based framework offers a different option: model averaging. We plot the hazard and survival curves based on weighted averages of multiple models. The weights can be based on various criteria. One approach would be to use the model weights from the LOO or the WAIC. As an example, here we use the LOO weights for the quadratic and cubic models.

```{r}
nd <- tibble(period = 6:15)

pp <-
  pp_average(b2.quad, b2.cubic,
             weights = "loo",
             newdata = nd,
             method = "pp_expect") %>% 
  data.frame() %>% 
  bind_cols(nd)
```

The pp_average() function works much like fitted() or predict(). If you input models and perhaps newdata, it will return estimates that are the weighted averages of the specified models. With the weights = "loo" argument, we indicated our desired weights were those from the LOO, just as we computed earlier with the model_weights() function. With the method = "pp_expect" argument, we indicated we wanted fitted values like we would get from fitted().

```{r}
# hazard
p1 <-
  pp %>% 
  ggplot(aes(x = period)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              alpha = 1/5) +
  geom_line(aes(y = Estimate)) +
  scale_x_continuous("Time bin", breaks = 6:15, limits = c(6, 15)) +
  ylab("hazard") +
  theme(panel.grid = element_blank())

# survival
p2 <-
  pp %>% 
  select(-Est.Error) %>% 
  #bind_rows(tibble(Estimate = 0, Q2.5 = 0, Q97.5 = 0, period = 0)) %>% 
  arrange(period) %>% 
  mutate_at(vars(Estimate:Q97.5), .funs = ~ cumprod(1 - .)) %>% 
  
  ggplot(aes(x = period)) +
  geom_hline(yintercept = .5, color = "white") +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              alpha = 1/5) +
  geom_line(aes(y = Estimate)) +
  scale_x_continuous("Time bin", breaks = 6:15) +
  scale_y_continuous("survival", breaks = c(0, .5, 1), limits = c(0, 1)) +
  theme(panel.grid = element_blank())

# combine
(p1 | p2) + 
  plot_annotation(title = "Behold the fitted hazard and survival curves based on a weighted\naverage of the quadratic and cubic models!")
```




Interpreting parameters from linear, quadratic, and cubic specifications.

For the polynomial models in this section, Singer and Willett used the  
TIMEâˆ’c  specification for period where c is a centering constant. 
  
```{r}
ptb_data_ind <-
  ptb_data_ind %>% 
  mutate(period_9 = period - 9)

# how do the two `period` variables compare?
ptb_data_ind %>% 
  distinct(period, period_9)
```

```{r}
plan(multicore)

b2.quad.centered <-
  update(b2.quad,
         newdata = ptb_data_ind,
         event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2),
         chains = 4, cores = 8, iter = 3000, warmup = 1000,
         seed = 12,
         file = "models/b2.quad.centered")
```

```{r}
print(b2.quad.centered)
```

The â€œflipover pointâ€ is the point at which the quadratic function reaches its peak or trough. Using posterior samples:

```{r}
as_draws_df(b2.quad.centered) %>% 
  transmute(c  = 9,
            a1 = b_period_9,
            a2 = b_Iperiod_9E2) %>% 
  mutate(`flipover point` = c - 0.5 * (a1 / a2)) %>% 
  
  ggplot(aes(x = `flipover point`, y = 0)) +
  stat_halfeye(.width = c(.5, .95)) +
  scale_x_continuous(breaks = 6:15, limits = c(11,13)) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())
```

Just as each parameter has a posterior distribution, the flipover point, which is a function of two of the parameters, also has a posterior distribution. To understand what this flipover distribution means, it might be helpful to look at it in another way. For that, weâ€™ll employ fitted().

```{r}
nd <- 
  tibble(period = seq(from = 6, to = 15, by = .1)) %>% 
  mutate(period_9 = period - 9)

f <-
  fitted(b2.quad.centered,
         newdata = nd,
         summary = F,
         scale = "linear") %>% 
  data.frame() %>% 
  pivot_longer(everything()) %>% 
  bind_cols(expand(nd,
                   iter = 1:8000,
                   nesting(period, period_9)))

f %>% 
  glimpse()
```

Logit hazard spaghetti plot

```{r}
f %>% 
  # how many lines would you like?
  filter(iter <= 60) %>% 
  
  ggplot(aes(x = period, y = value, group = iter)) +
  geom_line(alpha = 1/2) +
  ylab("logit hazard") +
  coord_cartesian(xlim = c(6, 15),
                  ylim = c(-4, 0)) +
  theme(panel.grid = element_blank())
```

Now fit a cubic model using period_9, as the measure of time.

```{r}
plan(multicore)

b2.cubic.centered <-
  update(b2.cubic,
         newdata = ptb_data_ind,
         event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2) + I(period_9^3),
         chains = 4, cores = 8, iter = 3000, warmup = 1000,
         seed = 12,
         file = "models/b2.cubic.centered")
```

```{r}
print(b2.cubic.centered)
```

```{r}
# extract the posterior draws
draws <-
  as_draws_df(b2.cubic.centered) %>% 
  transmute(c  = 9,
            a1 = b_period_9,
            a2 = b_Iperiod_9E2,
            a3 = b_Iperiod_9E3)

# flipover point with "+" in the numerator
p1 <-
  draws %>% 
  mutate(`flipover point 1` = c + (- a2 + sqrt(a2^2 - 3 * a1 * a3)) / (3 * a3)) %>% 
  filter(!is.na(`flipover point 1`)) %>% 
  filter(`flipover point 1` > -50 & `flipover point 1` < 50) %>% 
  
  ggplot(aes(x = `flipover point 1`, y = 0)) +
  stat_halfeyeh(.width = c(.5, .95),) +
  annotate(geom = "text",
           x = -30, y = .85,
           label = "italic(c)+frac(-alpha[2]+sqrt(alpha[2]^2-3*alpha[1]*alpha[3]), 3*alpha[3])",
           hjust = 0, family = "Times", parse = T) +
  scale_y_continuous(NULL, breaks = NULL) +
  coord_cartesian(xlim = c(-50, 20))

# flipover point with "-" in the numerator
p2 <-
  draws %>% 
  mutate(`flipover point 2` = c + (- a2 - sqrt(a2^2 - 3 * a1 * a3)) / (3 * a3)) %>% 
  filter(!is.na(`flipover point 2`)) %>% 
  
  ggplot(aes(x = `flipover point 2`, y = 0)) +
  stat_halfeyeh(.width = c(.5, .95)) +
  annotate(geom = "text",
           x = 9.2, y = .85,
           label = "italic(c)+frac(-alpha[2]-sqrt(alpha[2]^2-3*alpha[1]*alpha[3]), 3*alpha[3])",
           hjust = 0, family = "Times", parse = T) +
  scale_y_continuous(NULL, breaks = NULL)

# combine!
(p1 | p2) & theme(panel.grid = element_blank())
```

```{r}
# redifine the `newdata`
nd <- 
  tibble(period = seq(from = -40, to = 15, by = .1)) %>% 
  mutate(period_9 = period - 9)

# employ `fitted()` and wrangle
f <-
  fitted(b2.cubic.centered,
         newdata = nd,
         summary = F,
         scale = "linear") %>% 
  data.frame() %>% 
  pivot_longer(everything()) %>% 
  bind_cols(expand(nd,
                   iter = 1:8000,
                   nesting(period, period_9)))

# plot!
f %>% 
  filter(iter <= 30) %>% 
  ggplot(aes(x = period, y = value, group = iter)) +
  geom_line(alpha = 1/2) +
  ylab("logit hazard") +
  coord_cartesian(xlim = c(-40, 15),
                  ylim = c(-100, 100)) +
  theme(panel.grid = element_blank())
```

On the region to the right of 0 on the x-axis, the plot looks a lot like the one for the quadratic model. But look at how wildly the lines fan out on the left side of 0. Since thatâ€™s the region where we find the second flipover point, all that uncertainty got baked into its marginal posterior. Just because I think it looks cool, hereâ€™s a version of that plot with lines corresponding to all 4,000 posterior draws.
 
```{r}
f %>% 
  ggplot(aes(x = period, y = value, group = iter)) +
  geom_line(alpha = 1/10, linewidth = 1/10) +
  ylab("logit hazard") +
  coord_cartesian(xlim = c(-40, 15),
                  ylim = c(-25, 25)) +
  theme(panel.grid = element_blank())
```

## cloglog 

the clog-log transformation yields the logarithm of the negated logarithm of the probability of event nonoccurrence

```{r}
# simulate the data
tibble(p = seq(from = .00001, to = .99999, length.out = 1e4)) %>% 
  mutate(logit   = log(p / (1 - p)),
         cloglog = log(-log(1 - p))) %>% 
  pivot_longer(-p) %>% 
  mutate(name = factor(name,
                       levels = c("logit", "cloglog"),
                       labels = c("Logit", "Complementary log-log"))) %>% 
  
  # plot
  ggplot(aes(x = p, y = value, color = name)) +
  geom_hline(yintercept = 0, color = "white") +
  geom_line(linewidth = 1) +
  scale_color_viridis_d(NULL, option = "A", end = .6) +
  scale_y_continuous("transformed hazard probability", 
                     breaks = -3:3 * 5, limits = c(-15, 15)) +
  xlab("hazard probability") +
  theme(legend.background = element_rect(fill = "grey92"),
        legend.key = element_rect(fill = "grey92", color = "grey92"),
        legend.position = "inside",
        legend.position.inside = c(.25, .85),
        panel.grid = element_blank())
```

Both transformations extend to the full âˆ’âˆž to âˆž parameter space. But whereas the logit is symmetric around zero and has a memorable point corresponding to  p=.5  (i.e., 0), the clog-log is asymmetric and has a less-intuitive point corresponding to  p=.5  (i.e., -0.3665129). Though somewhat odd, the advantage of the clog-log is that
it provides a discrete-time statistical model for hazard that has a built-in proportional hazards assumption, and not a proportional odds assumption (as in the case of the logit link). 

Display sample hazard functions on different scales,â€ namely the logit and clog-log. 

Little trick: Instead of life tables, we use 4 bayesian regression models with weakly-regularizing priors:

```{r}
## logit
plan(multicore)

# con == 1 and incon == 0
b3.neutral <-
  brm(data = ptb_data_ind %>% filter(con == 0 & incon == 0),
      family = binomial,
      event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b3.neutral")

# con=1 and incon=0
b3.con <-
  brm(data = ptb_data_ind %>% filter(con == 1 & incon == 0),
      family = binomial,
      event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b3.con")

# con=0 and incon=1
b3.incon <-
  brm(data = ptb_data_ind %>% filter(con == 0 & incon == 1),
      family = binomial,
      event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b3.incon")

## clog-log
# neutral
b3.neutral.cloglog <-
  brm(data = ptb_data_ind %>% filter(con == 0 & incon == 0),
      family = binomial(link = cloglog),
      event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b3.neutral.cloglog")

# con
b3.con.cloglog <-
  brm(data = ptb_data_ind %>% filter(con == 1 & incon==0),
      family = binomial(link = cloglog),
      event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b3.con.cloglog")
# incon
b3.incon.cloglog <-
  brm(data = ptb_data_ind %>% filter(con == 0 & incon==1),
      family = binomial(link = cloglog),
      event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b3.incon.cloglog")

```


```{r}
make_fitted <- function(fit, scale, ...) {
  
  fitted(fit,
         newdata = nd,
         scale = scale,
         ...) %>% 
    data.frame() %>% 
    bind_cols(nd)
}
```

Before we can make our version of Figure 12.5, we will redefine our nd data for fitted(), pump our four fit objects into our custom make_fitted() function from earlier, and wrangle a little.

```{r}
nd <-
  tibble(period = 6:15) %>% 
  mutate(d6  = if_else(period == 6, 1, 0),
         d7  = if_else(period == 7, 1, 0),
         d8  = if_else(period == 8, 1, 0),
         d9  = if_else(period == 9, 1, 0),
         d10 = if_else(period == 10, 1, 0),
         d11 = if_else(period == 11, 1, 0),
         d12 = if_else(period == 12, 1, 0),
         d13 = if_else(period == 13, 1, 0),
         d14 = if_else(period == 14, 1, 0),
         d15 = if_else(period == 15, 1, 0))

f <-
  bind_rows(make_fitted(b3.neutral, scale = "linear"),
            make_fitted(b3.con, scale = "linear"),
            make_fitted(b3.incon, scale = "linear"),
            make_fitted(b3.neutral.cloglog, scale = "linear"),
            make_fitted(b3.con.cloglog, scale = "linear"),
            make_fitted(b3.incon.cloglog, scale = "linear")) %>% 
  mutate(condition   = rep(str_c("cond = ", c(1:3, 1:3)), each = n() / 6),
         link = rep(c("logit", "clog-log"), each = n() / 2))

f %>% glimpse()
```

```{r}
f %>% 
  ggplot(aes(x = period, group = interaction(condition, link),
             color = condition)) +
  geom_line(aes(y = Estimate, linetype = link)) +
  scale_color_viridis_d(NULL, option = "A", end = .6) +
  scale_x_continuous("grade", breaks = 6:15, limits = c(6, 15)) +
  ylab("transformed hazard probability") +
  coord_cartesian(ylim = c(-6, 0)) +
  theme(panel.grid = element_blank())
```

Now fit proper models to the data (logit vs. cloglog link)

```{r}
# logit
plan(multicore)

b3.general.prime.logit <-
  brm(data = ptb_data_ind,
      family = binomial,
      event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15 + con + incon,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 11,
      file = "models/b3.general.prime.logit")

# clog-log
b3.general.prime.cloglog <-
  brm(data = ptb_data_ind,
      family = binomial(link = cloglog),
      event | trials(1) ~ 0 + d6 + d7 + d8 + d9 + d10 + d11 + d12 + d13 + d14 + d15 + con + incon,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b3.general.prime.cloglog")
```

Compare posterior means:

```{r}
pars <-
  bind_rows(fixef(b3.general.prime.logit)  %>% data.frame() %>% rownames_to_column("par"),
            fixef(b3.general.prime.cloglog) %>% data.frame() %>% rownames_to_column("par")) %>% 
  mutate(link = rep(c("logit", "clog-log"), each = n() / 2),
         par  = factor(par, levels = c(str_c("d", 6:15), "con", "incon")))

pars %>%
  select(par, link, Estimate) %>% 
  pivot_wider(names_from = link,
              values_from = Estimate) %>% 
  select(par, `clog-log`, logit) %>% 
  mutate_if(is.double, round, digits = 4)
```

Compare in a coefficient plot

```{r}
pars %>% 
  ggplot(aes(x = link, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_pointrange() +
  labs(x = NULL, 
       y = "transformed hazard") +
  coord_flip() +
  theme(axis.text.y = element_text(hjust = 0),
        panel.grid = element_blank()) +
  facet_wrap(~ par, ncol = 1)
```

Instead of comparing them with deviance values, we will compare the two models using Bayesian information criteria. For simplicity, weâ€™ll focus on the LOO.

```{r}
b3.general.prime.logit <- add_criterion(b3.general.prime.logit, c("loo", "waic"))
b3.general.prime.cloglog <- add_criterion(b3.general.prime.cloglog, c("loo", "waic"))


loo_compare(b3.general.prime.logit, b3.general.prime.cloglog, criterion = "loo") %>% print(simplify = F)
```

```{r}
model_weights(b3.general.prime.logit, b3.general.prime.cloglog, weights = "loo") %>% round(digits = 3)
```

From a LOO perspective, theyâ€™re basically the same. The parameter summaries are also quite similar between the two models. A coefficient plot might make it easy to see. â€œNumerical similarity is common when fitting identical models with alternate link functions (and net risks of event occurrence are low) and suggests that choice of a link function should depend on other considerationsâ€ (p. 423).

Convert estimates of both models into hazard metric

```{r}
pars %>% 
  filter(par != "con" & par != "incon") %>% 
  mutate(Estimate = if_else(str_detect(link, "logit"),
                            1 / (1 + exp(-1 * Estimate)),
                            1 - exp(-exp(Estimate)))) %>%
  select(par, link, Estimate) %>% 
  pivot_wider(names_from = link,
              values_from = Estimate) %>% 
  select(par, `clog-log`, logit) %>% 
  mutate(`clog-log - logit` = `clog-log` - logit) %>% 
  mutate_if(is.double, round, digits = 4)
```

Exponentiate the estimates for con gives odds vs. hazard ratio's:

```{r}
# left
p1 <-
  as_draws_df(b3.general.prime.logit) %>% 
  ggplot(aes(x = b_con %>% exp(), y = 0)) +
  stat_halfeye(.width = c(.5, .95), na.rm = T) +
  scale_x_continuous("b_con (exponentiated)") +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "b3.general.prime.logit (logit link)",
       subtitle = "Exponentiating this parameter yields an odds ratio.") +
  coord_cartesian(xlim = c(1, 3)) +
  theme(panel.grid = element_blank())

# right
p2 <-
  as_draws_df(b3.general.prime.cloglog) %>% 
  ggplot(aes(x = b_con %>% exp(), y = 0)) +
  stat_halfeye(.width = c(.5, .95)) +
  scale_x_continuous("b_con (exponentiated)", limits = c(1, 3)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "b3.general.prime.cloglog (clog-log link)",
       subtitle = "Exponentiating this parameter yields a hazard ratio.") +
  theme(panel.grid = element_blank())

# combine
p1 | p2
```

## Time-varying predictors

Skipped.

## the linear additivity assumption: uncovering violations and simple solutions

### Interactions between predictors

There are at least two circumstances when a guided search for interactions is crucial:

* When theory (or common sense!) suggests that two (or more) predictors will interact in the prediction of the outcome. If you hypothesize the existence of interactions a priori, your search will be targeted and efficient.
* When examining the effects of â€œquestionâ€ predictor(s), variables whose effects you intend to emphasize in your report. You need to be certain that these predictorsâ€™ effects do not differ according ot levels of other important predictors, lest you misinterpret your major findings.

Let's add trial to the model, and check for interactions between con and trial, and between incon and trial.

```{r}
dataPS <- read_csv("data/inputfile_hazard_modeling_PS2016.csv")

head(dataPS)
summary(dataPS) # trial for each subject / 71 bl and 22 tr within block / 26602 rows
```

```{r}
dataPS <- dataPS %>% mutate(trial_c = (trial - 1000)/1000,
                            period_9 = period - 9)

dataPS <- dataPS %>% filter(period > 5) # 12840 rows left
summary(dataPS)



# create dummy variables for each time period and level of condition
dataPS <- dataPS %>% 
                    mutate(d6 = if_else(period == 6, 1, 0),
                           d7 = if_else(period == 7, 1, 0),
                           d8 = if_else(period == 8, 1, 0),
                           d9 = if_else(period == 9, 1, 0),
                           d10 = if_else(period == 10, 1, 0),
                           d11 = if_else(period == 11, 1, 0),
                           d12 = if_else(period == 12, 1, 0),
                           d13 = if_else(period == 13, 1, 0),
                           d14 = if_else(period == 14, 1, 0),
                           d15 = if_else(period == 15, 1, 0),
                           con = if_else(condition == 2, 1, 0),
                           incon = if_else(condition == 3, 1, 0))
head(dataPS)
```

Let's fit models with and without interactions.

```{r}
plan(multicore)

b4_general_nointeractions <-
  brm(data = dataPS,
      family = binomial(link="cloglog"),
      event | trials(1) ~ 0 + d6 + d7+ d8 + d9 + d10  + d11  + d12  + d13  + d14  + d15  +  con + incon + trial_c,
      prior(normal(0, 4), class = b),
      chains = 4, cores = 8, iter = 3000, warmup = 1000,
      seed = 12,
      file = "models/b4_general_nointeractions")

b4_general_interactions2 <-
   brm(data = dataPS,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + d6+ d7 + d8 + d9 + d10  + d11  + d12  + d13  + d14  + d15 + con + incon + trial_c + con:trial_c + incon:trial_c,
       prior(normal(0, 4), class = b),
         chains = 4, cores = 8, iter = 3000, warmup = 1000,
         seed = 12,
         file = "models/b4_general_interactions2")
```

```{r}
print(b4_general_nointeractions)
print(b4_general_interactions2)
fixef(b4_general_interactions2)[13,1]
```

```{r}
b4_general_nointeractions <- add_criterion(b4_general_nointeractions, criterion = "waic")
b4_general_interactions2 <- add_criterion(b4_general_interactions2, criterion = "waic")

loo_compare(b4_general_nointeractions, b4_general_interactions2, criterion = "waic") %>% print(simplify = F)
model_weights(b4_general_nointeractions, b4_general_interactions2, weights = "waic") %>% round(digits = 3)
```


### nonlinear effects (of trial number...)

```{r}
plan(multicore)

b4_general_interactions_nonlinear2 <-
   brm(data = dataPS,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + d6+ d7 + d8 + d9 + d10  + d11  + d12  + d13  + d14  + d15 + con + incon + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c,
       prior(normal(0, 4), class = b),
         chains = 4, cores = 8, iter = 3000, warmup = 1000,
         seed = 12,
         file = "models/b4_general_interactions_nonlinear2")
```

```{r}
print(b4_general_interactions_nonlinear2)
```

```{r}
b4_general_interactions_nonlinear2 <- add_criterion(b4_general_interactions_nonlinear2, criterion = "waic")

loo_compare(b4_general_nointeractions, b4_general_interactions2, b4_general_interactions_nonlinear2, criterion = "waic") %>% print(simplify = F)
model_weights(b4_general_nointeractions, b4_general_interactions2, b4_general_interactions_nonlinear2, weights = "waic") %>% round(digits = 3)
```

## The proportionality assumption: test whether con and incon interact with time

```{r}
plan(multicore)

b4_general_interactions_nonlinear_noprop3 <-
   brm(data = dataPS,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + d6+ d7 + d8 + d9 + d10  + d11  + d12  + d13  + d14  + d15 + con + con:period_9 + incon + incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c,
       prior(normal(0, 4), class = b),
         chains = 4, cores = 8, iter = 3000, warmup = 1000,
         seed = 12,
         file = "models/b4_general_interactions_nonlinear_noprop3")
```

```{r}
print(b4_general_interactions_nonlinear_noprop3)
```

```{r}
b4_general_interactions_nonlinear_noprop3 <- add_criterion(b4_general_interactions_nonlinear_noprop3, criterion = "waic")

loo_compare(b4_general_nointeractions, b4_general_interactions2, b4_general_interactions_nonlinear2,b4_general_interactions_nonlinear_noprop3, criterion = "waic") %>% print(simplify = F)
model_weights(b4_general_nointeractions, b4_general_interactions2, b4_general_interactions_nonlinear2, b4_general_interactions_nonlinear_noprop3, weights = "waic") %>% round(digits = 3)
```

## the no observed heterogeneiety assumption
## residual analysis

```{r}
residuals(b4_general_interactions_nonlinear2) %>% 
  str()
```

Plot residuals for first 500 rows. 

```{r}
residuals(b4_general_interactions_nonlinear2) %>% 
  data.frame() %>% 
  bind_cols(dataPS) %>% 
  mutate(event = factor(event),
         id = 1:n()) %>% 
  
  filter(id < 500) %>%
  
  ggplot(aes(x = id, y = Estimate, ymin = Estimate-Est.Error, ymax = Estimate+Est.Error, color = event)) +
  geom_hline(yintercept = 0, color = "white") +
  geom_pointrange(fatten = 3/4, alpha = 1/2) +
  scale_color_viridis_d(option = "A", end = .6) +
  ylab("residual") +
  theme(legend.position = "top", 
        panel.grid = element_blank()) 
```

Note. Our estimated stand. error of residuals is very high...

Pull Pareto k estimates

```{r}
loo(b4_general_interactions_nonlinear2)$diagnostics %>% 
  data.frame() %>% 
  glimpse()
```

Plot Pareto k estimates

```{r}
loo(b4_general_interactions_nonlinear2)$diagnostics %>% 
  data.frame() %>% 
  # attach the `id` values
  bind_cols(dataPS) %>% 
  mutate(id = 1:n()) %>%
  
  ggplot(aes(x = id, y = pareto_k)) +
  geom_point(alpha = 3/4) + 
  geom_text(data = . %>% filter(pareto_k > .2),
            aes(x = id + 2, label = id),
            size = 3, hjust = 0) +
  theme(panel.grid = element_blank())
```

# ############
## Fit multilevel model

Start with random intercept model, and these priors:

```{r}
priors <- c(
  set_prior("normal(0, 1)", class = "b"), # for beta parameters 
  set_prior("student_t(7.61, 0, 1.57)", class = "b", coef = "Intercept"), # flat prior for intercept
  set_prior("normal(0, 1)", class = "sd")
  #set_prior("lkj(2)", class = "cor")
)
```


```{r}
get_prior(event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2) + con + con:period_9 + incon +                                 incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c + 
                              (1 | pid),
          data = dataPS, family = binomial(link="cloglog"))
```


```{r}
plan(multicore)

b5_multilevel_1 <-
   brm(data = dataPS,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2) + con + con:period_9 + incon +                                 incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c + 
                              (1 | pid),
       prior = priors,
       chains = 4, cores = 8, iter = 3000, warmup = 1000,
       control = list(adapt_delta = 0.99), #, stepsize = 0.01, max_treedepth = 20),
       seed = 12,
       file = "models/b5_multilevel_1")
```

```{r}
print(b5_multilevel_1)
get_prior(b5_multilevel_1)
```

Result: rejecting intial values, but all 4 chains start sampling. No error messages.

Non-maximal random intercepts + slopes models:

Test1: (1 + period_9 + I(period_9^2)| pid)

```{r}
priors <- c(
  set_prior("normal(0, 1)", class = "b"), # for beta parameters 
  set_prior("student_t(7.61, 0, 1.57)", class = "b", coef = "Intercept"), # flat prior for intercept
  set_prior("normal(0, 1)", class = "sd"),
  set_prior("lkj(2)", class = "cor")
)
```


```{r}
get_prior(event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2) + con + con:period_9 + incon +                                 incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c + 
                              (1 + period_9 + I(period_9^2)| pid),
          data = dataPS, family = binomial(link="cloglog"))
```


```{r}
plan(multicore)

b5_multilevel_2c <-
   brm(data = dataPS,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2) + con + con:period_9 + incon +                                 incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c + 
                              (1 + period_9 + I(period_9^2) | pid),
       prior = priors,
       chains = 4, cores = 8, iter = 3000, warmup = 1000,
       control = list(adapt_delta = 0.99, step_size = 0.04, max_treedepth = 12),
       seed = 12, init = "0",
       file = "models/b5_multilevel_2c")
```

```{r}
print(b5_multilevel_2c)
get_prior(b5_multilevel_2c)
```

For 2a, all chains finished unexpectedly. So add init="0" for model 2b.

For 2b, 800 seconds per chain. Also, 5 transitions (of 8000) ended with a divergence. Set stepsize to 0.04 and max_treedepth to 12 for model 2c.

For 2c, 1100 seconds per chain. 1 of 8000 transitions ended with a divergence.


Test2: (1 + period_9 + I(period_9^2) + con + incon | pid)

```{r}
priors <- c(
  set_prior("normal(0, 1)", class = "b"), # for beta parameters 
  set_prior("student_t(7.61, 0, 1.57)", class = "b", coef = "Intercept"), # flat prior for intercept
  set_prior("normal(0, 1)", class = "sd"),
  set_prior("lkj(2)", class = "cor")
)
```


```{r}
get_prior(event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2) + con + con:period_9 + incon +                                 incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c + 
                              (1 + period_9 + I(period_9^2) + con + incon | pid),
          data = dataPS, family = binomial(link="cloglog"))
```


```{r}
plan(multicore)

b5_multilevel_2d <-
   brm(data = dataPS,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2) + con + con:period_9 + incon +                                 incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c + 
                              (1 + period_9 + I(period_9^2) + con + incon | pid),
       prior = priors,
       chains = 4, cores = 8, iter = 3000, warmup = 1000,
       control = list(adapt_delta = 0.99, step_size = 0.04, max_treedepth = 12),
       seed = 12, init = "0",
       file = "models/b5_multilevel_2d")
```

```{r}
print(b5_multilevel_2d)
get_prior(b5_multilevel_2d)
```

For 2d, 1460 ms per chain on average. 1 transition ended with a divergence. Increase adapt_delta to 0.999 for next model.


Test3: (1 + period_9 + I(period_9^2) + con + incon + con:period_9 + incon:period_9| pid)

```{r}
priors <- c(
  set_prior("normal(0, 1)", class = "b"), # for beta parameters 
  set_prior("student_t(7.61, 0, 1.57)", class = "b", coef = "Intercept"), # flat prior for intercept
  set_prior("normal(0, 1)", class = "sd"),
  set_prior("lkj(2)", class = "cor")
)
```


```{r}
get_prior(event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2) + con + con:period_9 + incon +                                 incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c + 
                              (1 + period_9 + I(period_9^2) + con + incon | pid),
          data = dataPS, family = binomial(link="cloglog"))
```


```{r}
plan(multicore)

b5_multilevel_2e <-
   brm(data = dataPS,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2) + con + con:period_9 + incon +                                 incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c + 
                              (1 + period_9 + I(period_9^2) + con + incon + con:period_9 + incon:period_9| pid),
       prior = priors,
       chains = 4, cores = 8, iter = 3000, warmup = 1000,
       control = list(adapt_delta = 0.999, step_size = 0.04, max_treedepth = 12),
       seed = 12, init = "0",
       file = "models/b5_multilevel_2e")
```

```{r}
print(b5_multilevel_2e)
get_prior(b5_multilevel_2e)
```

For 2e, 3750 ms per chain on average. 0 transitions ended with a divergence.


Test4: Maximal multilevel model : (1 + period_9 + I(period_9^2) + con + incon + con:period_9 + incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c | pid)

```{r}
priors <- c(
  set_prior("normal(0, 1)", class = "b"), # for beta parameters 
  set_prior("student_t(7.61, 0, 1.57)", class = "b", coef = "Intercept"), # flat prior for intercept
  set_prior("normal(0, 1)", class = "sd"),
  set_prior("lkj(2)", class = "cor")
)
```

```{r}
plan(multicore)

b5_multilevel_2f <-
   brm(data = dataPS,
       family = binomial(link="cloglog"),
       event | trials(1) ~ 0 + Intercept + period_9 + I(period_9^2) + con + con:period_9 + incon +                                 incon:period_9 + trial_c + I(trial_c^2) + con:trial_c + incon:trial_c + 
                              (1 + period_9 + I(period_9^2) + con + incon + con:period_9 + incon:period_9 + trial_c +                                         I(trial_c^2) + con:trial_c + incon:trial_c| pid),
       prior = priors,
       chains = 4, cores = 8, iter = 3000, warmup = 1000,
       control = list(adapt_delta = 0.999, step_size = 0.04, max_treedepth = 12),
       seed = 12, init = "0",
       file = "models/b5_multilevel_2f")
```

```{r}
print(b5_multilevel_2f)
get_prior(b5_multilevel_2f)
```

For 2f, 3850  ms per chain on average.  0 transition ended with a divergence.






